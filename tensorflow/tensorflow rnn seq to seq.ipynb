{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61bf39d",
   "metadata": {},
   "source": [
    "# seq to seq version 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a18262",
   "metadata": {},
   "source": [
    "## default version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e4abde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:39:23.371893Z",
     "start_time": "2024-01-29T06:39:09.987555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
      "tensorflow 2.5.3\n",
      "numpy 1.19.5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "rc('font', family='Malgun Gothic') #윈도우용, 한글깨짐 방지\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print('tensorflow', tf.__version__)\n",
    "print('numpy', np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2bb920c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:39:23.387352Z",
     "start_time": "2024-01-29T06:39:23.383328Z"
    }
   },
   "outputs": [],
   "source": [
    "sources = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "targets = [['나는', '배가', '고프다'],\n",
    "           ['텐서플로우는', '매우', '어렵다'],\n",
    "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dadbcc39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:39:23.398631Z",
     "start_time": "2024-01-29T06:39:23.393645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0,\n",
      " 'I': 1,\n",
      " 'a': 2,\n",
      " 'changing': 3,\n",
      " 'deep': 4,\n",
      " 'difficult': 5,\n",
      " 'fast': 6,\n",
      " 'feel': 7,\n",
      " 'for': 8,\n",
      " 'framework': 9,\n",
      " 'hungry': 10,\n",
      " 'is': 11,\n",
      " 'learning': 12,\n",
      " 'tensorflow': 13,\n",
      " 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "s_vocab = ['<pad>'] + s_vocab\n",
    "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
    "\n",
    "pprint(source2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e04bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:39:23.416979Z",
     "start_time": "2024-01-29T06:39:23.408218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<bos>': 1,\n",
      " '<eos>': 2,\n",
      " '<pad>': 0,\n",
      " '고프다': 3,\n",
      " '나는': 4,\n",
      " '딥러닝을': 5,\n",
      " '매우': 6,\n",
      " '배가': 7,\n",
      " '변화한다': 8,\n",
      " '빠르게': 9,\n",
      " '어렵다': 10,\n",
      " '위한': 11,\n",
      " '텐서플로우는': 12,\n",
      " '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab\n",
    "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
    "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
    "\n",
    "pprint(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca76bc3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:39:35.241726Z",
     "start_time": "2024-01-29T06:39:35.234616Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, diction, mode='source'):\n",
    "    assert mode in ['source', 'target'], 'source와 target 중 선택 필요'\n",
    "    \n",
    "    if mode == 'source' : \n",
    "        s_input = list(map(lambda sentence : [diction.get(token) for token in sentence], sequences))\n",
    "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
    "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding='post', truncating='post')\n",
    "        \n",
    "        return s_len, s_input\n",
    "    \n",
    "    elif mode == 'target' : \n",
    "        t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
    "        t_input = list(map(lambda sentence : [diction.get(token) for token in sentence], t_input))\n",
    "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
    "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding='post', truncating='post')\n",
    "        \n",
    "        t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
    "        t_output = list(map(lambda sentence : [diction.get(token) for token in sentence], sequences))\n",
    "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding='post', truncating='post')\n",
    "    \n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b595c38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:39:36.700900Z",
     "start_time": "2024-01-29T06:39:36.681778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences = sources, max_len = s_max_len,\n",
    "                           diction = source2idx, mode = 'source')\n",
    "print(s_len, s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b4c945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:39:37.000688Z",
     "start_time": "2024-01-29T06:39:36.984393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
      " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  0  0  0  0  0  0  0  0  0]\n",
      " [12  6 10  0  0  0  0  0  0  0  0  0]\n",
      " [12  5 11 13  0  0  0  0  0  0  0  0]\n",
      " [12  6  9  8  0  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences = targets, max_len = t_max_len,\n",
    "                                       diction = target2idx, mode = 'target')\n",
    "print(t_len, t_input, t_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1685cfbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:40:42.985761Z",
     "start_time": "2024-01-29T06:40:42.964360Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59db14d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T09:02:27.865273Z",
     "start_time": "2024-01-18T09:02:27.817876Z"
    }
   },
   "outputs": [],
   "source": [
    "#hyper parameter\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 4\n",
    "learning_rate = 0.005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size // batch_size\n",
    "embedding_dim = 32\n",
    "units = 32\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d58919e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T09:03:27.604655Z",
     "start_time": "2024-01-18T09:03:27.600667Z"
    }
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "    return tf.keras.layers.GRU(units, return_sequences=True,\n",
    "                              return_state=True, recurrent_initializer = 'glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "978e7e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T09:09:08.938752Z",
     "start_time": "2024-01-18T09:09:08.905889Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        output = tf.reshape(output, (-1, output.shape[2])) # output shape == (batch_size * 1, hidden_size)\n",
    "        \n",
    "        x = self.fc(output) # output shape == (batch_size * 1, vocab)\n",
    "        \n",
    "        return x, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cda48ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T09:10:02.554778Z",
     "start_time": "2024-01-18T09:10:02.539347Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17405a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T09:14:31.701068Z",
     "start_time": "2024-01-18T09:14:31.695084Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fucntion(real, pred):\n",
    "    mask = 1 - np.equal(real,0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = real, logits = pred) * mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f9e68b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T09:17:12.137650Z",
     "start_time": "2024-01-18T09:17:12.132563Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer = optimizer, encoder = encoder, decoder = decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b272a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for ii, (s_len, s_input, t_len, t_input, t_output): in enumerate(data):\n",
    "            loss = 0\n",
    "            with tf.GradientTape() as tape:\n",
    "                enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "                dec_hidden = enc_hidden\n",
    "                dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
    "                \n",
    "                for tt in range(1, t_input.shape[1]):\n",
    "                    \n",
    "                    predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_output)\n",
    "                    loss += loss_function(t_input[:, tt], predictions)\n",
    "                    dec_input = tf.expand_dims(t_input[:, tt], 1) #using teacher forcing ->>> 확인 필요\n",
    "                    \n",
    "            batch_loss = (loss / int(t_input.shape[1]))\n",
    "            total_loss += batch_loss\n",
    "            variables = endocer.variables * decoder.variables\n",
    "            gradient = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(gradient, variables))\n",
    "            \n",
    "        if epoch % 10 == 0 :\n",
    "            print('epoch {} loss {:.4f} batch loss {:.4f}'.format(epoch,\n",
    "                                                                 total_loss / n_batch,\n",
    "                                                                 batch_loss.numpy()))\n",
    "            checkpoint,save(file_prefix = checkpoint_prefix)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(sentence, encoder, decoder, inp_lang, targ_lang, \n",
    "               max_length_inp, max_length_targ):\n",
    "    inputs = [inp_lang[ii] for ii in sentence.split(' ')]\n",
    "    inputs = pad_sequences([inputs, maxlen=max_length_inp, padding='post'])\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder([inputs, hidden])\n",
    "    \n",
    "    for tt in range(max_length_targ):\n",
    "        predictions, dec_hidden = decoder(dec_input, dec_hidden, enc_out)\n",
    "        predicted_id = tf.argmax(predictions[0].numpy())\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "        \n",
    "        if idx2target.get(predicted_id) == '<eos>':\n",
    "            return result, sentence\n",
    "        \n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    return result, sentence\n",
    "\n",
    "sentence = 'I feel hungry'\n",
    "\n",
    "result, output_sentence = prediction(sentence, encoder, decoder,\n",
    "                                    source2idx, target2idx,\n",
    "                                    s_max_len, t_max_len)\n",
    "\n",
    "print(sentence)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d89ab",
   "metadata": {},
   "source": [
    "## using attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16283c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:40:57.282867Z",
     "start_time": "2024-01-29T06:40:57.272596Z"
    }
   },
   "outputs": [],
   "source": [
    "#hyper parameter 이전 부분까지는 같음\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "learning_rate = 0.005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size // batch_size\n",
    "embedding_dim = 32\n",
    "units = 128\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a7a25ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T06:40:57.850758Z",
     "start_time": "2024-01-29T06:40:57.846770Z"
    }
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "    return tf.keras.layers.GRU(units, return_sequences=True,\n",
    "                              return_state=True, recurrent_initializer = 'glorot_uniform',\n",
    "                              recurrent_activation = 'sigmoid') #activation 추가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c0772f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T07:59:43.357801Z",
     "start_time": "2024-01-29T07:59:43.346780Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention (기존 이후 추가되는 영역)\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \n",
    "        #attention위해서 추가됨\n",
    "        \n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        #기존 영역\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis = -1) #임베딩과 attention 결합\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        \n",
    "        output = tf.reshape(output, (-1, output.shape[2])) # output shape == (batch_size * 1, hidden_size)\n",
    "        \n",
    "        x = self.fc(output) # output shape == (batch_size * 1, vocab)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f774855b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T07:59:43.634207Z",
     "start_time": "2024-01-29T07:59:43.585931Z"
    }
   },
   "outputs": [],
   "source": [
    "# 동일 코드\n",
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
    "\n",
    "def loss_fucntion(real, pred):\n",
    "    mask = 1 - np.equal(real,0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = real, logits = pred) * mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer = optimizer, encoder = encoder, decoder = decoder)\n",
    "\n",
    "#create writer for tensorboard(신규 추가)\n",
    "summary_writer = tf.summary.create_file_writer(logdir = checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59718805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:02.094151Z",
     "start_time": "2024-01-29T07:59:44.212922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.0396 batch loss 0.9902\n",
      "epoch 10 loss 0.0356 batch loss 0.8903\n",
      "epoch 20 loss 0.0302 batch loss 0.7548\n",
      "epoch 30 loss 0.0215 batch loss 0.5376\n",
      "epoch 40 loss 0.0143 batch loss 0.3575\n",
      "epoch 50 loss 0.0080 batch loss 0.2000\n",
      "epoch 60 loss 0.0033 batch loss 0.0829\n",
      "epoch 70 loss 0.0013 batch loss 0.0315\n",
      "epoch 80 loss 0.0006 batch loss 0.0150\n",
      "epoch 90 loss 0.0004 batch loss 0.0088\n"
     ]
    }
   ],
   "source": [
    "# 동일 코드\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "            dec_hidden = enc_hidden\n",
    "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
    "\n",
    "            for tt in range(1, t_input.shape[1]):\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                loss += loss_fucntion(t_input[:, tt], predictions)\n",
    "                dec_input = tf.expand_dims(t_input[:, tt], 1) #using teacher forcing ->>> 확인 필요\n",
    "\n",
    "        batch_loss = (loss / int(t_input.shape[1]))\n",
    "        total_loss += batch_loss\n",
    "        variables = encoder.variables + decoder.variables\n",
    "        gradient = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "            \n",
    "    if epoch % 10 == 0 :\n",
    "        print('epoch {} loss {:.4f} batch loss {:.4f}'.format(epoch,\n",
    "                                                             total_loss / n_batch,\n",
    "                                                             batch_loss.numpy()))\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d8faf07c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:02.243555Z",
     "start_time": "2024-01-29T08:00:02.221479Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    hidden = [tf.zeros((1,units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
    "    \n",
    "    for tt in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[tt] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "        \n",
    "        if idx2target.get(predicted_id) == '<eos>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37d11067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:02.410072Z",
     "start_time": "2024-01-29T08:00:02.389329Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize' : 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0897c521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:02.543942Z",
     "start_time": "2024-01-29T08:00:02.527658Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, \n",
    "                                                inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "    print('Input : {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e2683d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T07:58:19.282651Z",
     "start_time": "2024-01-29T07:58:19.196544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1c575196310>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2c581763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T08:00:02.876740Z",
     "start_time": "2024-01-29T08:00:02.644245Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : I feel hungry\n",
      "Predicted translation: 나는 배가 고프다 <eos> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10331\\AppData\\Local\\Temp/ipykernel_10864/4264259835.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "C:\\Users\\10331\\AppData\\Local\\Temp/ipykernel_10864/4264259835.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = 'I feel hungry'\n",
    "\n",
    "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
