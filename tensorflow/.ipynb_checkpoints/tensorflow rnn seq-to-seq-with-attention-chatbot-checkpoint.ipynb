{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61bf39d",
   "metadata": {},
   "source": [
    "# seq to seq version 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a18262",
   "metadata": {},
   "source": [
    "## default version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e4abde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:06:07.759929Z",
     "start_time": "2024-02-23T01:05:53.411327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
      "tensorflow 2.5.3\n",
      "numpy 1.19.5\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "rc('font', family='Malgun Gothic') #윈도우용, 한글깨짐 방지\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print('tensorflow', tf.__version__)\n",
    "print('numpy', np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ff7116",
   "metadata": {},
   "source": [
    "## using attention and chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e32ea51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:07:02.964016Z",
     "start_time": "2024-02-23T01:07:01.128279Z"
    }
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import time\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "import pandas as pd\n",
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9189723a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:51.467100Z",
     "start_time": "2024-02-23T01:08:51.457128Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    \n",
    "    dataDF = pd.read_csv('./ChatBotData.csv', header=0)\n",
    "    question, answer = list(dataDF['Q']), list(dataDF['A'])\n",
    "    return question, answer\n",
    "\n",
    "def preproLikeMorphlized(data):\n",
    "    \n",
    "    morphAnalyzer = Twitter() \n",
    "    result_data = list()\n",
    "    for seq in data:\n",
    "        #Twitter.morphs 함수를 통해 토크나이즈 된 리스트 객체 받고, 다시 공백문자 기준으로 해서 문자열 재구성\n",
    "        morphlizedSeq = \" \".join(morphAnalyzer.morphs(seq.replace(' ','')))\n",
    "        result_data.append(morphlizedSeq)\n",
    "    return result_data\n",
    "\n",
    "def dataTokenizer(data):\n",
    "    words = [] #토크나이징 해서 담을 배열\n",
    "    for sentence in data:\n",
    "        '''\n",
    "        filters = \"([~.,!?\\\"':;)(])\"\n",
    "        위 필터와 같은 값들을 정규화 표현식으로 \"\"으로 모두 변환\n",
    "        ''' \n",
    "        sentence = re.sub(change_filter, \"\", sentence)\n",
    "        for word in sentence.split():\n",
    "            words.append(word)\n",
    "    #토크나이징과 정규표현식을 통해 만들어진 값 넘겨준다.\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctua\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "    w = w.rstrip().strip()\n",
    "    w = '<start> ' + w + ' <end>' #문장에 start, end token 추가함 (띄어쓰기 주의)\n",
    "    return w\n",
    "\n",
    "def create_dataset(data, num_examples):\n",
    "    word_pairs = [[preprocess_sentence(ii)] for ii in data[:num_examples]]\n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9aac9a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:52.075905Z",
     "start_time": "2024-02-23T01:08:52.069924Z"
    }
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "class LanguageIndex():\n",
    "    def __init__(self, lang):\n",
    "        self.lang = lang\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab = set()\n",
    "        \n",
    "        self.create_index()\n",
    "        \n",
    "    def create_index(self):\n",
    "        for phrase in self.lang:\n",
    "            self.vocab.update(phrase.split(' '))\n",
    "        \n",
    "        self.vocab = sorted(self.vocab)\n",
    "        \n",
    "        self.word2idx['<pad>'] = 0\n",
    "        \n",
    "        for index, word in enumerate(self.vocab):\n",
    "            self.word2idx[word] = index + 1\n",
    "        \n",
    "        for word, index in self.word2idx.items():\n",
    "            self.idx2word[index] = word                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90dad9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:52.375565Z",
     "start_time": "2024-02-23T01:08:52.358244Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples):\n",
    "    data_df = pd.read_csv(path, header = 0)\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "    question = create_dataset(question, num_examples)\n",
    "    answer = create_dataset(answer, num_examples)\n",
    "    \n",
    "    print(len(question))\n",
    "    \n",
    "    pairs = [question[ii] + answer[ii] for ii in range(num_examples)]\n",
    "    \n",
    "    inp_lang = LanguageIndex(qq for qq, aa in pairs)\n",
    "    targ_lang = LanguageIndex(aa for qq, aa in pairs)\n",
    "    \n",
    "    input_tensor = [[inp_lang.word2idx[ss] for ss in qq.split(' ')] for qq, aa in pairs]\n",
    "    target_tensor = [[targ_lang.word2idx[ss] for ss in aa.split(' ')] for qq, aa in pairs]\n",
    "    \n",
    "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "    \n",
    "    input_tensor = pad_sequences(input_tensor, maxlen=max_length_inp, padding='post')\n",
    "    target_tensor = pad_sequences(target_tensor, maxlen=max_length_tar, padding='post')\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58208192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:53.191730Z",
     "start_time": "2024-02-23T01:08:52.653092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9458, 9458, 2365, 2365)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 11823\n",
    "\n",
    "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset('./ChatBotData.csv', num_examples)\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e37921b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:53.250851Z",
     "start_time": "2024-02-23T01:08:53.234419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d0c891a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:53.350581Z",
     "start_time": "2024-02-23T01:08:53.337935Z"
    }
   },
   "outputs": [],
   "source": [
    "## create a tf.data dataset\n",
    "\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "N_BATCH = BATCH_SIZE //  BATCH_SIZE #1\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527abf07",
   "metadata": {},
   "source": [
    "# cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7298fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:53.939162Z",
     "start_time": "2024-02-23T01:08:53.934790Z"
    }
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "    return tf.keras.layers.GRU(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be0844a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:54.200278Z",
     "start_time": "2024-02-23T01:08:54.168354Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        print(\"state: {}\".format(state.shape))\n",
    "        print(\"output: {}\".format(state.shape))\n",
    "              \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8046b70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:54.346689Z",
     "start_time": "2024-02-23T01:08:54.336683Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        # * `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "                \n",
    "        #* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, 1)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        # * `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        # * `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # * `merged vector = concat(embedding output, context vector)`\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c608cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:54.560217Z",
     "start_time": "2024-02-23T01:08:54.534202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13422 9856 256 1024 64\n"
     ]
    }
   ],
   "source": [
    "print(vocab_inp_size, vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dccc065e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:54.734118Z",
     "start_time": "2024-02-23T01:08:54.718656Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cf34fff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:08:54.983379Z",
     "start_time": "2024-02-23T01:08:54.953247Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de3372",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-23T01:10:20.776Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (64, 1024)\n",
      "output: (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "#GPU 설정\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder(inp, hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)\n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        \n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "          checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e63747d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:10:09.533017Z",
     "start_time": "2024-02-23T01:10:09.524318Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.idx2word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee06c080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:10:09.774748Z",
     "start_time": "2024-02-23T01:10:09.765688Z"
    }
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb1eaeef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:10:10.024851Z",
     "start_time": "2024-02-23T01:10:10.008444Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90159cf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:10:10.374936Z",
     "start_time": "2024-02-23T01:10:10.276029Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (9856, 256) and (14, 32) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13156/4152603127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# restoring the latest checkpoint in checkpoint_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2262\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2263\u001b[1;33m       \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2264\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2265\u001b[0m       raise errors_impl.NotFoundError(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     \"\"\"\n\u001b[0;32m   2150\u001b[0m     \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2151\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2153\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1336\u001b[0m         \u001b[0mgraph_view\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m         options=options)\n\u001b[1;32m-> 1338\u001b[1;33m     base.CheckpointPosition(\n\u001b[0m\u001b[0;32m   1339\u001b[0m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0;32m   1340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mcurrent_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvisit_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m       new_restore_ops, new_tensor_saveables, new_python_saveables = (\n\u001b[1;32m--> 969\u001b[1;33m           \u001b[0mcurrent_position\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    970\u001b[0m           ._single_restoration_from_checkpoint_position(\n\u001b[0;32m    971\u001b[0m               \u001b[0mcheckpoint_position\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_single_restoration_from_checkpoint_position\u001b[1;34m(self, checkpoint_position, visit_queue)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                                                []).append(child_position)\n\u001b[0;32m   1006\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mchild_position\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m           \u001b[1;31m# This object's correspondence is new, so dependencies need to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m           \u001b[1;31m# visited. Delay doing it so that we get a breadth-first dependency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mbind_object\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;31m# method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_create_or_restore_slot_variable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m           optimizer_object._create_or_restore_slot_variable(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    308\u001b[0m               slot_variable_position=CheckpointPosition(\n\u001b[0;32m    309\u001b[0m                   \u001b[0mcheckpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_create_or_restore_slot_variable\u001b[1;34m(self, slot_variable_position, slot_name, variable)\u001b[0m\n\u001b[0;32m   1395\u001b[0m       \u001b[1;31m# If we've either made this slot variable, or if we've pulled out an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m       \u001b[1;31m# existing slot variable, we should restore it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1397\u001b[1;33m       \u001b[0mslot_variable_position\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslot_variable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m       \u001b[1;31m# We didn't make the slot variable. Defer restoring until it gets created\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    975\u001b[0m       \u001b[0mpython_saveables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_python_saveables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m     restore_ops.extend(\n\u001b[1;32m--> 977\u001b[1;33m         current_position.checkpoint.restore_saveables(\n\u001b[0m\u001b[0;32m    978\u001b[0m             tensor_saveables, python_saveables))\n\u001b[0;32m    979\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[1;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[0;32m    306\u001b[0m             (\"Saveable keys changed when validating. Got back %s, was \"\n\u001b[0;32m    307\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m--> 308\u001b[1;33m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0m\u001b[0;32m    309\u001b[0m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0;32m    310\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    337\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    321\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m           \u001b[0mrestore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    113\u001b[0m     for saveable, restored_tensors in zip(self._saveable_objects,\n\u001b[0;32m    114\u001b[0m                                           structured_restored_tensors):\n\u001b[1;32m--> 115\u001b[1;33m       restore_ops[saveable.name] = saveable.restore(\n\u001b[0m\u001b[0;32m    116\u001b[0m           restored_tensors, restored_shapes=None)\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_var_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m       \u001b[0mrestored_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[0m\u001b[0;32m    132\u001b[0m           self.handle_op, self._var_shape, restored_tensor)\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mshape_safe_assign_variable_handle\u001b[1;34m(handle, shape, value, name)\u001b[0m\n\u001b[0;32m    306\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[0mvalue_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   return gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m    310\u001b[0m       handle, value_tensor, name=name)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \"\"\"\n\u001b[0;32m   1160\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shapes (9856, 256) and (14, 32) are incompatible"
     ]
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa1125b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-23T01:10:15.103015Z",
     "start_time": "2024-02-23T01:10:14.825254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: (1, 1024)\n",
      "output: (1, 1024)\n",
      "Input: <start> 뭐라도 배워볼까 . <end>\n",
      "Predicted translation: <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10331\\AppData\\Local\\Temp/ipykernel_13156/1800777997.py:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "C:\\Users\\10331\\AppData\\Local\\Temp/ipykernel_13156/1800777997.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm8AAAEwCAYAAADhBpY3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUBUlEQVR4nO3de7Sld13f8c+XmclMEpqQG5hEBEIKwaXWlHAVcLVUuUhclVtLywqgJS1lxVqWlVYXXoutqRcK2EtqwRaRLARszaJNBGzVBBSDtbAqNMGEhDIp5IrYMMlM5ts/9j64c+ZM5swk5zznd/brtdZZs/fz7DPznfXMnPM+z34u1d0BAGAMD5t6AAAA1k+8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEcpap6UVWdPPUcwHISbwBH7w1Jzp56CGA57Zx6AICtrKqes8biU5I8papOP8ynXdvdd2/gWMASKzemBzi8qvrdo/yUTvLq7r5hI+YBEG8AAAPxtinAEVTVK5N8OcmdSfbaqwZMyZ43gCOoqruTXJHk9MxOVDglye8neXeS93f3gQnHA5aMeAM4gqq6pbvPXHh+apJnJ/m+JE9O8qbufsdU8wHLRbwBHEFVvb+7X3KYdecm+aUkN3f3RZs7GbCMxBvAEVTVh5PcluRLSX4vyYe6+9aF9ZXkvO7+9EQjAkvERXq3gar6rqp6zdRzwDb2rUneleRTSZ6f5I+r6leq6pwk6RnhBmwKe94GV1UPS/LxJDuSXNDd9008Emw7axzzdlySH1j56O73TjQasITE2+Dme9y+Mcm9Sa7r7v8w8Uiw7VTVm7v7R9ZYfm6S30jynO6+bfMnA5aReBtYVe3JbK/bc5Icl+Sq7j5/2qk4VlV1dnd/Yeo5ODpVtau79089B7A8HPM2tkuSXN7dd3X3l5J8tKpeNvVQHLM/mHoA1q+qzkwS4Qabr6qeUVUXTj3HVOx5G1RVPSLJNUme3N375ssel+R93f3kKWfjUFX18O7+s1XLntXdVy88v99xVWxtVXVddz9h6jlgGc3vOby7u5869SxTsOdtXPsyO85m38qC7r4xyYXzyxawtax1O6UPrHruJ6ktqqpOWPjYs7J4vu5RVXXWyp44Z37Dxqqqv57kfyf5+Pzx0rHnDTZBVd3a3Wc80LKq2tvdZ23+dBxJVX01ya4k+zO7GO8TV/a8VdUXkxxMckJ3n2yPHGyc+RUWrk1yYWb/J3+1u5857VSbz563gVXV29dYtqOqfnaKeXhAa/2U5CenQXT38Uk+Pf919dfNP52/3b2yd9Web9g435vkI939he7+XJIbquo7Jp5p0+2cegAelBeusWxPkr+Z5Ac3eRaOXlXVT688TvLwKYfhiHrVr0daDjyEqur4JP8wybctLP6ZJG9L8qFJhpqIeBtQVf1Okq9LcnZVXbdq9SMzu+4UY3BR5fGcVlU/GV8/YbPtTvKy7r5rZUF3f6qq3lhVD+vug9ONtrl88RnT65OcluQ9SV67at0d3f2pzR+JY9Dd/aaVJ1X1d6YchqMiumGTzaPtrjWW//6mDzMx8TaglTirqn/e3b899Tw8ZLztNobbu/snqupvTz0IsJzE26DmlwN5RpJ/OfUsrMvpVXXvwvOKE4a2KxEOD6Gq+lDW8f+qu79zE8bZEsTboLq7q+qbqmpndx+Yeh6O6PipB+DYVdX+JDvmv964evX81+Or6vNJHrWpw8H29ysLj89L8vLMTlK4M8k5SS5K8nMTzDUZ13kb2Pxtmxck+VdJbs7sWlNJku7eO9VcHBt3WNi6qmr3wtOD3b1/4TpvZ3X33qo6K7PrTqW7b5pmUtjequqaJBd1958sLLsgyT/q7r8x3WSbS7wNrKoOd2ZNd/eOTR2GB62qvq67/+/Uc7A+VXV9d//FqeeAZVJVN3X3Y9ZYfmN3P26KmabgmJuBdffDDvMh3La4qnpmVT1+cZlwG86zph4AltBdVXXe4oKq+oYsWc8s1V8WtpBXJHna1ENw7Lr7i1PPAEvop5JcVVWvr6q/WlWvTvKbSf79tGNtLicsDGy+5+ZfJPnGJMctruvucyYZikPMfypc7eGZnYG61rok2etEFID76+73VdWdSS5J8roktyV5S5LLppxrsznmbWDzOy38XpK7k5yd5ANJ3pDk8u5eqp9CtrL5GYid9d/zspN8Z3d/ZuOmYr2q6pas//IfNX/tc7v70xs3FbDMxNvAVg7crKqnJHltd19cVack+WB3P3Pq+WA7qKpDDo5eww8n+VSSK+bP93b3/o2bCpZXVZ2T5PwkJy4u7+7/OM1Em8/bpmO7r6p2JLkuyZOSpLvvrKqvn3YsjlZV3eCt7q3pgS77UVVvTvKrSf40yZdcIgQ2VlV9f5JLk/xRZtd5W9FJxBtDuCqz6928s6oOVtWbkpya5JaJ52KVqnrHqkU3dvdPLTw/WFW77K3Zuqrq+Um+O7Mflt7W3fclOT2z+wwDm+OHkjyzu/9w6kGm5GzTsV2S5PL544uSnJvkzCSvmmwiDufFSa6Zf/xxkgtXrb8ryUmbPBPrVFUvy+wK7p9J8tQk75qvujuzu2f86yT/bZrpYKnsW/ZwS+x5G92zuvu/J197a+dV87dRnz7pVKzlqysnkVTV2Znd3uV+65OckOT2zR6MdXljkgu7+4Ykb62qj86Phbsnye75cmDjXVFV39HdH5p6kCmJt7G9I7P7un1Nd99XVb+cxJXft5YjnRm0P8nuI7yG6ZyyKtA+ntn/sXuT/Luqest8eWV2hxPHL8LGODnJr1XV1UnudxvI7r54mpE2n3gbUFW9IcmeJI+oqh9etfrxmYUAY7kviTtjbF0Hquq47r53/vyRSe7I7P/aP03yXyabDJbLTUl+YeohpibexnR8Zse37cyhe9juSPI9mz4RR7L6Gm9PqqqPLqw7L45B3cquSHLp/KSgZyT5pszOdntektsWb5INbJzu/ompZ9gKxNuAuvvNSVJV53b3a6aeh3V58cLjW5O8aI3XfG5zRuEY/GiSf5Pk5iTXJ/lb3X2wqjq+jsKmqqrnJXlpkpO7++XzO9Xcs0y3rPNFZ2Dd/ezF51X1qMwOnr55opE4jO7+2MLje5P89oTjcJS6++7Mzug+ZFV8HYVNM7/O2+syu5fpD8wXPzKzS4isPhFs23KHhYFV1W8l+bvdfX1VPS3JhzM7dur13f3uaaeD7a+q9mT2E78vpLAJquozSZ7d3bdW1Y3d/bj58uu7e2lO1PMT49ie2N3Xzx//ZJLvy+xaU1clEW9bRFUdzOHPNq1V61aen9/dn9zo2TiyqjruAVYfTLKr6v6HNC6c2AA8tHZ1963zx4tfO5fqbH0HSI/tK1W1o6qemOTx3f3e+T/qR0w8F/e3K8lxh/nYPf/4tSR/ZeW1wm1L2ZfZdfj2LXx8dY1lX1tXVd8yzaiw7f3Pqvp7iwuq6nuSLNVJQ/a8je3Xk/xWZu/3/2ySVNWpsV23lPltlNZUVZ/N7Fp9neTAA72WaXT3IT/kVtWPZXaW6S9OMBIss0uSfKSqXpnk9Kq6IrOb1L9w2rE2l2/yY/uRzG6Fta+73zNf9tjMrgbPFlJVP7pq0R3d/fbMbq90wgQjcRSqavXJCn8psz3fX1nr9d29NDfIhs3U3V+Y79l+UWY/+O5N8sru/vK0k20uJyzAJqiqLyd56/zpjiQv7e4nVNUfJHl+ZsdO/Zkb029NVfXOo3h5d/f3btgwwNITb4Oqqkcn+bfd/cKFZScl+U9J/lp3H5xqNg5VVZ/v7kfPH+9J8sl5vF2d5BVJvrD4etsP4P583/tzTlgYVHd/PsktVbV4XZvXJblymf4BD6QP8/jezG73sn/+cSBub7blVNUtVbX3AT4+OPWMsN35vvfnHPM2th9L8sGqen9mZylelOSp047EUdqf5Lzuvm7qQXhAT194fFGSk5K8ff780Ul+ftMnguXk+17E29C6+/9U1ZVJXpvZ9cHe293/b+KxWNuJCwe9L1437EDckH7L6+6bVh5X1R1J7ltZtvoab8DG8X1vRryN758luSazCPj2iWfh8H4js+u4rXj//NeOeIPJVdVp3X371HOwLkv/fU+8Da6776qqX05yWnffNfE4HEZ3v+Ywqw5kdqYpW9j8bNOVYxWflNldFc6dP/8L00zFQ+x9uf8PWGxRvu8523RbqKqdSXZ09z1TzwLbUVW96ggvua27nbQwsKo6Y+G2S2xxy/59T7wBAAzEpUIAAAYi3gAABiLetomqunjqGTg2tt3YbL9x2XZjW+btJ962j6X9R7wN2HZjs/3GZduNbWm3n3gDABjI0pxtelzt7j05ceoxNsz+3JNd2T31GBwD225s2377beMbSOzve7Krtu+2e8I33z31CBvq1tvvyxmnbd9rnH/ik/fc1t1nrLVuaS7Suycn5mn13KnHABhK7VyabxPbzpVXXTv1CDwIO8787E2HW+dtUwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgWzZeKuqV1fVh6eeAwBgK9my8QYAwKEeVLxV1Tc8VIOs4886papO2Kw/DwBgKzqmeKuqr6+qdyS5bNWyX6+qG6rquqr6Bwvrfryq3llVb6mqP6mqvYvr5695aVV9sqo+X1UfS3Leqj/2rCTXVtXFVbXjWOYGABjdUcXbfO/XpUn+a5LfTPKC+fLdST6S5MPdfU6SZyf5+1X1goVPf0mSK7v78UkuTHJpVZ07//znJvmFJK/o7kcnuSjJyxf/7O7+X0meleQJST5RVS8+2r8sAMDo1hVvVbWrqn4oyTVJPpfkL3f35d3d85e8KMnt3f2LSdLdX0zyS0leuvDbXN3dV87XfyLJHyU5f77u+5NcOg+0dPf1Sd62eo7uvqO7fzCz+Puuqrq6qr7tAea+uKqurapr9+ee9fxVAQC2tJ3rfN2OJKcluS9JzT9v/8L6c5J8c1V9bmHZcUk+tvB876rf884kJ84fn5tDY+3OB5hnZ5J9SfYkOf1wL+ruyzJ/a/ekOrUP9zoAgFGsa89bd+/r7jcm+fYkZyT5w6r6J1V18vwle5P8Tnc/duHjrO5+yTrnuC3J6pMfzln9oqr6lqp6d5L3ZPY27VO6+z+v888AABjeUR3zNn/b8seTPDXJwSQr4fTBJOcvHodWVU+pqseu87e+PMk/rqrHzD/3gsyOe/uaqnp6krcneVd3P727P7Dwti0AwFJY79um99PdX0nyM1X1c/Pnd1XVC5O8paremuSeJP8jySXr/C0vS/KoJL9bVZ3k40l+Psl3L7zm2u5+zrHMCwCwXdSy7Lw6qU7tp9Vzpx4DYCi185h+xmcLuPLma6cegQdhx5mf/UR3X7DWOndYAAAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYiHgDABiIeAMAGIh4AwAYyM6pBwBg6+oDB6YegWP0vLO+deoReFA+e9g19rwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADES8AQAMRLwBAAxEvAEADGTn1ANspKq6OMnFSbInJ0w8DQDAg7et97x192XdfUF3X7Aru6ceBwDgQdvW8QYAsN2INwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgYg3AICBiDcAgIGINwCAgVR3Tz3DpqiqW5PcNPUcG+j0JLdNPQTHxLYbm+03LttubNt9+z2mu89Ya8XSxNt2V1XXdvcFU8/B0bPtxmb7jcu2G9sybz9vmwIADES8AQAMRLxtH5dNPQDHzLYbm+03LttubEu7/RzzBgAwEHveAAAGIt4AAAYi3gAABiLeAAAGIt4AAAby/wFS3jlq72F9UAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('뭐라도 배워볼까.', encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657db9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
